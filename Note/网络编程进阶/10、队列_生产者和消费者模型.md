**IPC**：

进程间的通信，**I**：inter，**P**：process，**C**：communication

在抢票程序中，实现IPC(进程间的通信)，使用了文件作为共享数据空间，但是：

1、影响了执行效率

2、需要有添加互斥锁的代码

**每个进程之间的内存数据是相互独立的、隔离的，所以无法互通数据，所以可以通过Queue模块，去发送数据给其他进程，一个进程通过put方法放入数据，其他进程通过get方法取得数据**

所以在multiprocessing模块中，提供了**队列**和**管道**的方法，使用内存作为共享数据的空间：

队列 = 管道 + 锁，队列是以管道 + 互斥锁来实现的，引入类Queue

**队列的使用：**

1、不要放入大文件，应用于一个进程放入一个小数据，另一个进程去取数据

2、队列中可以放入无限多的数据，但是使用的是内存空间

```python
#队列的简单实现和原理，Queue实例包含put、get、full、empty方法：

from multiprocessing import Queue

#队列中存储的数据量设置为3
q = Queue(3)

#在队列中依次放入数据，如果超出设置的队列数量，会导致程序卡住
q.put("hello")
q.put([1,2,3,4])
q.put({'name':'alex','age':15})

#通过full方法，可以得知队列是否满员
print(q.full())

#在队列中取出数据。如果取完队列中的所有数据，再取就会导致程序卡住
print(q.get())
print(q.get())
print(q.get())

#通过empty方法可以得到队列中是否为空
print(q.empty())
'''
True
hello
[1, 2, 3, 4]
{'name': 'alex', 'age': 15}
True
'''
```



**生产者、消费者模型：**

1、程序中有两种角色：生产者（负责生产数据），消费者（负责提取数据）

**解决问题：**

1、平衡生产者和消费者的速度差

2、程序解开耦合

3、在生产环境中不会用到queue，而是使用Rabbitmq

**缺点：**

1、只能在同一台机器上put和get（同一块内存），影响了机器的稳定性

2、影响了性能

```python
import time

from multiprocessing import Process,Queue

#生产者一直生产包子，放入内存的共享空间
def producer(name,q):
    for i in range(10):
        q.put('%s生产了第%s个包子'%(name,i))
        print('%s生产了第%s个包子'%(name,i))
        time.sleep(1)

#消费者一直在内存的共享空间拿包子吃
def customer(name,q):
    while True:
        time.sleep(2)
        res = q.get()
        if res is None:
            break
        print('%s吃了%s'%(name,res))

if __name__ == '__main__':
    #添加队列对象
    q = Queue()
    p1 = Process(target = producter,args = ('alex',q))
    p2 = Process(target = producter,args = ('peiqi',q))
    p3 = Process(target = producter,args = ('egon',q))
    c1 = Process(target = customer,args = ('小明',q))
    c2 = Process(target = customer,args = ('小红',q))

    p.start()
    c.start()
    
    #在生产者完全生产完毕join()后，在共享内存中放入None，当消费者取到None时，停止取数据，否则程序会卡住运行，一直在取数据，不足之处是有几个生产者，就需要最后传入几个None，来让消费者知道某个生产者已经生产完毕
    p1.join()
    p2.join()
    q.put(None)
    q.put(None)
    
    print('主进程')
'''
egon生产了第0个包子
alex生产了第0个包子
peiqi生产了第0个包子
egon生产了第1个包子
alex生产了第1个包子
peiqi生产了第1个包子
egon生产了第2个包子
小红吃了egon生产了第0个包子
alex生产了第2个包子
小明吃了alex生产了第0个包子
peiqi生产了第2个包子
egon生产了第3个包子
alex生产了第3个包子
peiqi生产了第3个包子
egon生产了第4个包子
小红吃了peiqi生产了第0个包子
alex生产了第4个包子
peiqi生产了第4个包子
小明吃了egon生产了第1个包子
小红吃了alex生产了第1个包子
小明吃了peiqi生产了第1个包子
小红吃了egon生产了第2个包子
小明吃了alex生产了第2个包子
小红吃了peiqi生产了第2个包子
小明吃了egon生产了第3个包子
小红吃了alex生产了第3个包子
小明吃了peiqi生产了第3个包子
小红吃了egon生产了第4个包子
小明吃了alex生产了第4个包子
小红吃了peiqi生产了第4个包子
'''
```



为了解决不足之处，需要对每个生产者再次放入None，以让消费者知道生产完毕，才结束程序，所以引入了JoinableQueue类

```python
#生产者和消费者模型，JoinableQueue实例包含put、get、task_done、join方法
import time

from multiprocessing import Process,JoinableQueue

def producer(name,q):
    for i in range(2):
        q.put(i)
        print('%s 生产了%s包子'%(name,i))
        time.sleep(1)
    #子进程的join对于进程表示主进程需要等待子进程执行完毕，再执行主进程
    #生产者的join表示当消费者通过get取完数据时，等待消费者通过q.task_done()接口告知生产者get完毕
    q.join()

def customer(name,q):
    while True:
        time.sleep(2)
        res = q.get()
        print('%s吃了%s包子'%(name,res))
        #只有取完数据后，才会执行发送任务完成的信号
        q.task_done()

if __name__ == '__main__':
    q = JoinableQueue()
    p1 = Process(target = producer,args = ('生产者1',q))
    p2 = Process(target = producer,args = ('生产者2',q))
    p3 = Process(target = producer,args = ('生产者3',q))
    c1 = Process(target = customer,args = ('消费者1',q))
    c2 = Process(target = customer,args = ('消费者2',q))

    c1.daemon = True
    c2.daemon = True
    p1.start()
    p2.start()
    p3.start()
    c1.start()
    c2.start()
	
    #所以此时如果当所有的生产者都执行完毕后，也代表着所有的消费者都取完了数据，所以此时的消费者进程也就没有了意义，其进程内在一直循环get数据，所以将消费者进程设置为守护进程，主程序执行完毕后，就结束掉消费者进程
    p1.join()
    p2.join()
    p3.join()
    print('主进程')
```

