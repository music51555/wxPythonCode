**IPC**：

进程间的通信，**I**：inter，**P**：process，**C**：communication

在抢票程序中，实现IPC(进程间的通信)，使用了文件作为共享数据的空间，但是：

1、影响了执行效率

2、需要有添加互斥锁的代码



所以引入了Queue，来作为进程间通信的介质



**由于每个进程之间的内存数据是相互独立的、隔离的，所以无法互通数据，所以可以通过Queue模块，去发送数据给其他进程，一个进程通过put方法放入数据，其他进程通过get方法取得数据**

所以在multiprocessing模块中，提供了**队列**和**管道**的方法，使用内存作为共享数据的空间：

队列 = 管道 + 锁，队列是以管道 + 互斥锁来实现的，引入类from multiprocessing import Queue



**单线程中队列的简单使用：**

1、不要放入大文件，应用于一个进程放入一个小数据，另一个进程去取数据

2、队列中可以放入无限多的数据，但是使用的是内存空间

```python
from multiprocessing import Queue

#队列中存储的数据量设置为3
q = Queue(3)

#在队列中依次放入数据
q.put("hello")
q.put([1,2,3,4])
q.put({'name':'alex','age':15})
#如果超出设置的队列数量，此时会导致程序卡住
q.put('first')

#通过full方法，可以得知队列是否满员，输出True或False
print(q.full())

#在队列中取出数据。
print(q.get())
print(q.get())
print(q.get())
#如果取完队列中的所有数据，再取就会导致程序卡住
print(q.get())

#通过empty方法可以得到队列中是否为空，输出True或False
print(q.empty())
'''
True
hello
[1, 2, 3, 4]
{'name': 'alex', 'age': 15}
True
'''
```



**简单使用方面总结：**

简单使用方面涉及到了**q.put()**放入数据，和**q.get()**取出数据，通过**q.full()**检查队列是否满载，通过**q.empty()**检查队列是否为空



**多进程中的队列使用：**

虽然设置了队列数为2，但是在task函数中put进去了3个数据，而且在foo函数内页顺利的取到了数据，这是因为在多线程中并发执行函数，在put的同时，另一个函数就通过了get得到了数据，所以可以顺利的放入3个数据，并且取到3个数据

```python
from multiprocessing import Process,Queue

def task(q):
    q.put(1)
    q.put(2)
    q.put(3)

def foo(q):
    print(q.get())
    print(q.get())
    print(q.get())

if __name__ == '__main__':
    #设置队列数为2
    q = Queue(maxsize=2)
    p1 = Process(target = task,args = (q,))
    p2 = Process(target = foo,args = (q,))

    p1.start()
    p2.start()
'''
1
2
3
'''
```



但是如何确定队列数maxsize = 2是起作用了呢，可以查看如下程序

```python
from multiprocessing import Process,Queue
import time

def task(q):
    q.put(1)
    print('put 1')
    q.put(2)
    print('put 2')
    q.put(3)
    print('put 3')

def foo(q):
    time.sleep(10)
    print(q.get())
    print(q.get())
    print(q.get())

if __name__ == '__main__':
    q = Queue(maxsize=2)
    p1 = Process(target = task,args = (q,))
    p2 = Process(target = foo,args = (q,))

    p1.start()
    p2.start()
#先输出了如下内容，表示在还没有get数据时，只能放入2个数据，full状态下再次放入数据，程序就会卡住
'''
put 1
put 2
'''
```



**进程间数据通信的Queue总结：**

使用Queue可以实现进程间的数据通信，一个进程通过put放入数据，另一个进程通过get取出数据



**生产者、消费者模型：**

1、程序中有两种角色：生产者（负责生产数据），消费者（负责提取数据）

**解决问题：**

1、平衡生产者和消费者的速度差

2、程序解开耦合

3、在生产环境中不会用到queue，而是使用Rabbitmq

**缺点：**

1、只能在同一台机器上put和get（同一块内存），影响了机器的稳定性

2、影响了性能

```python
import time

from multiprocessing import Process,Queue

#生产者一直生产包子，放入内存的共享空间
def producer(name,q):
    for i in range(10):
        q.put('%s生产了第%s个包子'%(name,i))
        print('%s生产了第%s个包子'%(name,i))
        time.sleep(1)

#消费者一直在内存的共享空间拿包子吃
def customer(name,q):
    while True:
        time.sleep(2)
        res = q.get()
        if res is None:
            break
        print('%s吃了%s'%(name,res))

if __name__ == '__main__':
    #添加队列对象
    q = Queue()
    p1 = Process(target = producter,args = ('alex',q))
    p2 = Process(target = producter,args = ('peiqi',q))
    p3 = Process(target = producter,args = ('egon',q))
    c1 = Process(target = customer,args = ('小明',q))
    c2 = Process(target = customer,args = ('小红',q))

    p1.start()
    p2.start()
    p3.start()
    c1.start()
    c2.start()

    #在生产者添加join()，让其完全生产完所有包子，此时在共享内存中放入None，当消费者取到None时，停止取数据，否则程序依然会继续使用get取数据，但是所有的数据都已经get取完毕，所以会导致程序卡住运行，一直在等待取数据。不足之处是有几个生产者，就需要最后传入几个None，来让所有等待取数据的get()操作消费者，知道生产者已经生产完毕
    p1.join()
    p2.join()
    p3.join()

    q.put(None)
    q.put(None)
    
    print('主进程')
'''
egon生产了第0个包子
alex生产了第0个包子
peiqi生产了第0个包子
egon生产了第1个包子
alex生产了第1个包子
peiqi生产了第1个包子
egon生产了第2个包子
小红吃了egon生产了第0个包子
alex生产了第2个包子
小明吃了alex生产了第0个包子
peiqi生产了第2个包子
egon生产了第3个包子
alex生产了第3个包子
peiqi生产了第3个包子
egon生产了第4个包子
小红吃了peiqi生产了第0个包子
alex生产了第4个包子
peiqi生产了第4个包子
小明吃了egon生产了第1个包子
小红吃了alex生产了第1个包子
小明吃了peiqi生产了第1个包子
小红吃了egon生产了第2个包子
小明吃了alex生产了第2个包子
小红吃了peiqi生产了第2个包子
小明吃了egon生产了第3个包子
小红吃了alex生产了第3个包子
小明吃了peiqi生产了第3个包子
小红吃了egon生产了第4个包子
小明吃了alex生产了第4个包子
小红吃了peiqi生产了第4个包子
'''
```



为了解决不足之处（put放入所有的数据后，需要放入None，来告知get数据已经put完毕），需要对每个生产者再次放入None，以让消费者知道生产完毕，才结束程序，所以引入了JoinableQueue类

```python
#生产者和消费者模型，JoinableQueue实例包含put、get、task_done、join方法
import time
from multiprocessing import Process,JoinableQueue

def producer(name,q):
    for i in range(10):
        q.put('%s的第%s个包子'%(name,i))
        print('%s生产了第%s个包子'%(name,i))
    #进程对象的join，表示主进程需要等待子进程执行完毕，再执行主进程
    #JoinableQueue对象的join表示当消费者通过get取完数据时，等待消费者通过q.task_done()接口告知生产者get完毕
    q.join()

def customer(name,q):
    while True:
        time.sleep(2)
        res = q.get()
        print('%s吃了%s'%(name,res))
        #取完数据后，由消费者发送取完数据的信号，告知生产者。而不是在使用Queue时，由生产者put放入None告知消费者生产完数据了，不用再等着取数据了，因为在消费者模型中依然在执行着get操作，等待着取数据
        #只有在get取完数据后，task_done才会生效
        q.task_done()

if __name__ == '__main__':
    q = JoinableQueue()
    p1 = Process(target=producer,args=('小马',q))
    p2 = Process(target=producer,args=('小风',q))
    p3 = Process(target=producer,args=('小云',q))
    p1.start()
    p2.start()
    p3.start()

    c1 = Process(target=customer,args=('alex',q))
    c2 = Process(target=customer,args=('wxx',q))
    #之所以设置消费者模型为守护进程，是因为生产者模型设置了join，主程序必须等待生产者模型生产完毕所有包子后，再执行主程序，而在生产者模型中又设置了JoinableQueue的join方法，表示消费者模型都已经取完了所有数据，所以在生产者的join之后，执行主程序的结束之时，将消费者模型一并结束，否则其消费者模型内仍然在取着数据，导致程序卡住
    c1.daemon=True
    c2.daemon=True
    c1.start()
    c2.start()
	
    #所以此时如果当所有的生产者都执行完毕后，也代表着所有的消费者都取完了数据，所以此时的消费者进程也就没有了意义，其进程内在一直循环get数据，导致程序卡住，所以将消费者进程设置为守护进程，主程序执行完毕后，就结束掉消费者进程
    p1.join()
    p2.join()
    p3.join()
    print('主进程')
'''
小马生产了第0个包子
小马生产了第1个包子
小马生产了第2个包子
小马生产了第3个包子
小马生产了第4个包子
小马生产了第5个包子
小马生产了第6个包子
小马生产了第7个包子
小马生产了第8个包子
小马生产了第9个包子
小风生产了第0个包子
小云生产了第0个包子
小风生产了第1个包子
小风生产了第2个包子
小云生产了第1个包子
小云生产了第2个包子
小云生产了第3个包子
小风生产了第3个包子
小云生产了第4个包子
小风生产了第4个包子
小风生产了第5个包子
小云生产了第5个包子
小风生产了第6个包子
小云生产了第6个包子
小风生产了第7个包子
小云生产了第7个包子
小风生产了第8个包子
小云生产了第8个包子
小风生产了第9个包子
小云生产了第9个包子
wxx吃了小马的第0个包子
alex吃了小马的第1个包子
wxx吃了小马的第2个包子
alex吃了小马的第3个包子
wxx吃了小马的第4个包子
alex吃了小马的第5个包子
wxx吃了小马的第6个包子
alex吃了小马的第7个包子
wxx吃了小马的第8个包子
alex吃了小马的第9个包子
wxx吃了小风的第0个包子
alex吃了小风的第1个包子
wxx吃了小云的第0个包子
alex吃了小风的第2个包子
wxx吃了小风的第3个包子
alex吃了小云的第1个包子
wxx吃了小风的第4个包子
alex吃了小云的第2个包子
wxx吃了小云的第3个包子
alex吃了小风的第5个包子
wxx吃了小云的第4个包子
alex吃了小风的第6个包子
wxx吃了小云的第5个包子
alex吃了小风的第7个包子
wxx吃了小风的第8个包子
alex吃了小云的第6个包子
wxx吃了小风的第9个包子
alex吃了小云的第7个包子
wxx吃了小云的第8个包子
alex吃了小云的第9个包子
主
'''
```



**总结JoinableQueue：**

在进程间通信，简单的使用put放入数据，和get取出数据，达到了数据通信的目的，但是在生产者模型放入所有的数据后，消费者模型也取完了所有的数据，但仍然在等着继续取数据，所以需要在生产者模型生产完毕put所有数据后，放入None，来告知消费者模型在get时，如果取到了None，那么就结束取数据的循环，这是不足之处。

所以为此引入了JoinableQueue，是因为在消费者get取完所有数据后，执行了q.task_done方法，告知了生产者模型的join方法，所以在main下等待所有生产者模型的join方法也执行完毕，此时会执行主进程，但是在此之前将消费者模型设置为了守护进程，所以主程序执行完毕后，消费者进程也被结束了