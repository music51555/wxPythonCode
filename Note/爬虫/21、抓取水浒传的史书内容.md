抓取水浒传的史书内容

**知识点1：**通过`BeautifulSoup`遍历请求页面，找到目标标签对象

**知识点2：**通过`select`方法得到的标签列表，里面的元素仍然支持`bs4`方法

**知识点3：**通过`find`方法得到不是列表，而是标签对象，仍然支持`bs4`方法

```python
import requests
from bs4 import BeautifulSoup

shuihu_url = 'http://www.shicimingju.com/book/shuihuzhuan.html'

headers = {
    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36',
}

shuihu_index = requests.get(url = shuihu_url, headers = headers).text

soup = BeautifulSoup(shuihu_index, 'lxml')

# 解耦，将打开文章正文链接，获取正文内容的操作存放在单独的函数中
def get_content(full_content_url):
    content_index = requests.get(url=full_content_url, headers=headers).text
    content_soup = BeautifulSoup(content_index, 'lxml')
    # 如果使用select获取文章详情页正文的class标签，那么得到的是结果永远是列表，存储的当前标签对象，包含所有子标签
    # content = content_soup.select('.chapter_content')[0].text
    
    # 使用find得到的直接是当前标签对象，并包含所有子标签
    content = content_soup.find('div', class_='chapter_content').text
    return content

title_list = soup.select('.book-mulu a')

# 打开文件存储每一篇文章的标题+正文
with open('shuihu.txt', 'w', encoding='utf-8') as f:
    for title_tag in title_list:
        content_url = title_tag['href']
        full_content_url = 'http://www.shicimingju.com'+content_url
        content = get_content(full_content_url)
        f.write(title_tag.text+'\n'+content+'\n\n')
```

